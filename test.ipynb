{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "source": "import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense,Dropout,Activation\nfrom keras.layers import Conv2D,MaxPooling2D,Flatten\nfrom keras.optimizers import SGD,Adam\nfrom keras.utils import np_utils\nfrom keras.datasets import mnist\n"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def load_data():\n    (x_train,y_train),(x_test,y_test)=mnist.load_data()\n    number = 10000\n    x_train = x_train[0:number]\n    y_train = y_train[0:number]\n    x_train = x_train.reshape(number,28*28)\n    x_test = x_test.reshape(x_test.shape[0],28*28)\n    x_train = x_train.astype('float32')\n    x_test = x_test.astype('float32')\n    y_train = np_utils.to_categorical(y_train,10)\n    y_test = np_utils.to_categorical(y_test,10)\n    x_train = x_train\n    x_test = x_test\n    \n    x_train = x_train/255\n    x_test = x_test/255\n    return (x_train,y_train),(x_test,y_test)"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "(x_train,y_train),(x_test,y_test) = load_data()"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 4, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(10000, 784)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "x_train.shape"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 5, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.05490196,\n       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.54509807,\n       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.15294118,\n       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "x_train[0]"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 6, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(10000, 10)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "y_train.shape"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 7, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "y_train[0]"
        }, 
        {
            "source": "1.define a set function\n2.goodness of function\n3.pick the best function", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Epoch 1/20\n10000/10000 [==============================] - 12s 1ms/step - loss: 0.0901 - acc: 0.1044\nEpoch 2/20\n10000/10000 [==============================] - 12s 1ms/step - loss: 0.0900 - acc: 0.1095\nEpoch 3/20\n10000/10000 [==============================] - 12s 1ms/step - loss: 0.0900 - acc: 0.1082\nEpoch 4/20\n10000/10000 [==============================] - 12s 1ms/step - loss: 0.0900 - acc: 0.1105\nEpoch 5/20\n10000/10000 [==============================] - 15s 2ms/step - loss: 0.0900 - acc: 0.1104\nEpoch 6/20\n10000/10000 [==============================] - 25s 3ms/step - loss: 0.0900 - acc: 0.1125\nEpoch 7/20\n10000/10000 [==============================] - 25s 2ms/step - loss: 0.0900 - acc: 0.1113\nEpoch 8/20\n10000/10000 [==============================] - 25s 3ms/step - loss: 0.0900 - acc: 0.1119\nEpoch 9/20\n10000/10000 [==============================] - 25s 3ms/step - loss: 0.0900 - acc: 0.1107\nEpoch 10/20\n10000/10000 [==============================] - 26s 3ms/step - loss: 0.0900 - acc: 0.1078\nEpoch 11/20\n10000/10000 [==============================] - 26s 3ms/step - loss: 0.0900 - acc: 0.1064\nEpoch 12/20\n10000/10000 [==============================] - 25s 3ms/step - loss: 0.0900 - acc: 0.1098\nEpoch 13/20\n10000/10000 [==============================] - 24s 2ms/step - loss: 0.0900 - acc: 0.1120\nEpoch 14/20\n10000/10000 [==============================] - 25s 2ms/step - loss: 0.0900 - acc: 0.1089\nEpoch 15/20\n10000/10000 [==============================] - 24s 2ms/step - loss: 0.0900 - acc: 0.1106\nEpoch 16/20\n10000/10000 [==============================] - 24s 2ms/step - loss: 0.0900 - acc: 0.1122\nEpoch 17/20\n10000/10000 [==============================] - 24s 2ms/step - loss: 0.0900 - acc: 0.1113\nEpoch 18/20\n10000/10000 [==============================] - 25s 2ms/step - loss: 0.0900 - acc: 0.1102\nEpoch 19/20\n10000/10000 [==============================] - 25s 3ms/step - loss: 0.0900 - acc: 0.1105\nEpoch 20/20\n10000/10000 [==============================] - 25s 3ms/step - loss: 0.0900 - acc: 0.1084\n10000/10000 [==============================] - 3s 278us/step\n\n Tolal loss on teating Set: 0.08997005969285965\n\nTest Acc: 0.11349999904632568\n[[0.10178589 0.11162784 0.10351507 ... 0.10586009 0.09652589 0.09917523]\n [0.10178585 0.11162782 0.1035151  ... 0.1058601  0.09652588 0.09917522]\n [0.10178586 0.11162785 0.1035151  ... 0.10586009 0.09652589 0.09917523]\n ...\n [0.10178585 0.11162785 0.10351509 ... 0.1058601  0.09652589 0.09917523]\n [0.10178584 0.11162782 0.1035151  ... 0.10586009 0.09652589 0.09917522]\n [0.10178582 0.11162782 0.10351507 ... 0.10586008 0.09652588 0.09917522]]\n"
                }
            ], 
            "source": "#step 1\uff1adefine a set function \nmodel = Sequential()\n\n#Dense\u8868\u793a\u662fFullConnectedLayer\uff1b\n#activation\u7684\u9009\u62e9\u6709 sigmoid\uff0csoftplus\uff0csoftsign\uff0crelu\uff0ctanh\uff0chard_sigmoid\uff0clinear  \n#units = 689 :\u8868\u793a\u4e2d\u95f4\u5c42\u6709689\u4e2aneural\nmodel.add(Dense(input_dim = 28*28,units = 689,activation='sigmoid'))\nmodel.add(Dense(units=689,activation = 'sigmoid'))\nmodel.add(Dense(units=689,activation = 'sigmoid'))\nfor i in range(10):\n    model.add(Dense(units=689,activation = 'sigmoid'))\n\n\nmodel.add(Dense(units=10,activation = 'softmax'))\n\n\n#step 2: goodness of function \n# 3.1 configure\n#optimizer\u7684\u9009\u62e9\u6709 SGD,RMSprop,Adagrad,Adadelta,Adam,Adamax,Nadam\nmodel.compile(loss='mse',optimizer = SGD(lr=0.1),metrics = ['accuracy'])\n\n\n#step 3:pick the best function \n\n# 3.2 find the optimal network parameters\n#x_train:Training data (Images)\n#y_train:Labels(digits)\n#batch_size = 100 : 100example in a mini-batch\n#epochs = 20\uff1arepeat 20 times\n# \u6ce8\uff1a\u82e5batch-size = 1 \uff0c\u5c31\u662fStochastic gradient descent\nmodel.fit(x_train,y_train,batch_size = 100,epochs = 20)\n\n\n#evaluate\u6b63\u786e\u7387\nresult = model.evaluate(x_test,y_test,batch_size = 10000)\nprint('\\n Tolal loss on teating Set:',result[0])\nprint('\\nTest Acc:',result[1])\n\n\nscore = model.predict(x_test)\nprint(score)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}